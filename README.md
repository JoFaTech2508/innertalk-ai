<p align="center">
  <img src="docs/app-icon-V2.png" alt="InnerTalk AI" width="128" />
</p>

<h1 align="center">InnerTalk AI</h1>

<p align="center">
  A private, offline desktop app for chatting with local AI models.<br>
  Powered by <a href="https://ollama.com">Ollama</a> — no setup, no cloud, no API keys.
</p>

<p align="center">
  <img src="https://img.shields.io/badge/macOS-12%2B-blue?style=flat-square&logo=apple" alt="macOS" />
  <img src="https://img.shields.io/badge/License-MIT-green?style=flat-square" alt="License" />
</p>

<p align="center">
  <img src="docs/screenshot-chat.png" alt="InnerTalk AI - Chat" width="800" style="border-radius: 12px;" />
</p>

---

## Features

- **100% Private** — everything runs locally, no cloud
- **Multiple Models** — download and switch between models
- **Chat History** — conversations persist across restarts
- **File Context** — attach files and folders as context
- **Streaming** — real-time responses with markdown and code blocks

<p align="center">
  <img src="docs/screenshot-settings.png" alt="InnerTalk AI - Settings" width="800" style="border-radius: 12px;" />
</p>

---

## Installation

1. Download the latest `.dmg` from [Releases](https://github.com/JoFaTech2508/innertalk-ai/releases)
2. Open the `.dmg` and drag the app to Applications
3. Launch the app — Ollama is bundled, no separate install needed

### Requirements

- macOS 12 or later (Apple Silicon or Intel)
- 8 GB RAM minimum (16 GB+ recommended for larger models)

---

<p align="center">
  Built with <a href="https://v2.tauri.app">Tauri</a>, <a href="https://react.dev">React</a>, and <a href="https://ollama.com">Ollama</a>
</p>

<p align="center">© 2026 JoFaTech2508</p>
